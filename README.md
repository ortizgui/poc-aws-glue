# POC AWS Glue - CSV Merger

Esta Ã© uma Prova de Conceito (POC) para demonstrar como usar AWS Glue para processar e combinar arquivos CSV usando Terraform para infraestrutura como cÃ³digo.

## ğŸ“‹ DescriÃ§Ã£o

O projeto cria um job AWS Glue que:
- LÃª 2 arquivos CSV de um bucket S3
- Combina os arquivos pelas colunas comuns (`id` e `categoria`)
- Salva o resultado em um novo arquivo CSV no S3
- Suporte para testes locais usando pandas

## ğŸ’° Calculadora de Custos AWS Glue

Este repositÃ³rio inclui uma **calculadora interativa de custos** para estimar o valor de execuÃ§Ã£o de jobs AWS Glue, disponÃ­vel via GitHub Pages.

### ğŸŒ Acessar a Calculadora

A calculadora estÃ¡ disponÃ­vel em: **[GitHub Pages - Calculadora de Custos](https://yourusername.github.io/poc-glue-tests/)**

*(Substitua `yourusername` pelo seu nome de usuÃ¡rio do GitHub)*

### âœ¨ Funcionalidades da Calculadora

A calculadora permite estimar custos considerando:

- â±ï¸ **Tempo de execuÃ§Ã£o** do job (em minutos)
- ğŸ–¥ï¸ **Tipo de Worker** (G.025X, G.1X, G.2X, G.4X, G.8X)
- ğŸ‘¥ **NÃºmero de Workers**
- ğŸ”„ **Tipo de ExecuÃ§Ã£o** (Standard ou FLEX com desconto)
- ğŸŒ **RegiÃ£o AWS**
- ğŸ“Š **Custos adicionais**:
  - Data Catalog (objetos armazenados)
  - Crawlers (tempo de execuÃ§Ã£o)

### ğŸ“Š Como Funciona

A calculadora utiliza os preÃ§os oficiais da AWS:
- **$0.44 por DPU-Hora** (faturado por segundo, mÃ­nimo de 1 minuto)
- **Desconto FLEX**: atÃ© 40% de economia (mÃ©dia)
- **Data Catalog**: Primeiro 1 milhÃ£o de objetos gratuito, depois $1.00 por 100.000 objetos/mÃªs
- **Crawlers**: Mesmo preÃ§o que ETL jobs, mÃ­nimo de 10 minutos

### ğŸš€ Configurar GitHub Pages

Para disponibilizar a calculadora no GitHub Pages:

1. **Ativar GitHub Pages no repositÃ³rio**:
   - VÃ¡ em `Settings` â†’ `Pages`
   - Em `Source`, selecione `Deploy from a branch`
   - Escolha a branch `main` e a pasta `/docs`
   - Clique em `Save`

2. **Acessar a calculadora**:
   - A URL serÃ¡: `https://yourusername.github.io/poc-glue-tests/`
   - Pode levar alguns minutos para ficar disponÃ­vel apÃ³s a primeira configuraÃ§Ã£o

### ğŸ“ Estrutura da Calculadora

```
docs/
â”œâ”€â”€ index.html      # Interface da calculadora
â”œâ”€â”€ styles.css      # Estilos e design responsivo
â”œâ”€â”€ calculator.js   # LÃ³gica de cÃ¡lculo
â””â”€â”€ .nojekyll       # ConfiguraÃ§Ã£o para GitHub Pages
```

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 Bucket     â”‚    â”‚   AWS Glue      â”‚    â”‚   S3 Bucket     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  input/         â”‚â”€â”€â”€â–¶â”‚  CSV Merger Job â”‚â”€â”€â”€â–¶â”‚  output/        â”‚
â”‚  â”œâ”€ vendas.csv  â”‚    â”‚                 â”‚    â”‚  â””â”€ merged.csv  â”‚
â”‚  â””â”€ clientes.csvâ”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
poc-glue-tests/
â”œâ”€â”€ docs/                # GitHub Pages - Calculadora de Custos
â”‚   â”œâ”€â”€ index.html      # Interface da calculadora
â”‚   â”œâ”€â”€ styles.css      # Estilos e design responsivo
â”‚   â”œâ”€â”€ calculator.js   # LÃ³gica de cÃ¡lculo
â”‚   â””â”€â”€ .nojekyll       # ConfiguraÃ§Ã£o para GitHub Pages
â”œâ”€â”€ src/
â”‚   â””â”€â”€ glue_job.py       # Script principal do Glue (funciona local + AWS)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ files/
â”‚       â”œâ”€â”€ vendas.csv    # Arquivo CSV de exemplo (5 colunas)
â”‚       â””â”€â”€ clientes.csv  # Arquivo CSV de exemplo (6 colunas)
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf          # ConfiguraÃ§Ã£o principal
â”‚   â”œâ”€â”€ variables.tf     # VariÃ¡veis
â”‚   â””â”€â”€ outputs.tf       # Outputs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-dev.sh     # Configurar ambiente de desenvolvimento
â”‚   â”œâ”€â”€ deploy.sh        # Script de deploy
â”‚   â”œâ”€â”€ destroy.sh       # Script de destruiÃ§Ã£o
â”‚   â”œâ”€â”€ test-local.sh    # Script de teste local
â”‚   â””â”€â”€ run-glue-job.sh  # Script para executar job
â”œâ”€â”€ venv/                # Ambiente virtual Python (criado automaticamente)
â”œâ”€â”€ output/              # Pasta para resultados locais
â”œâ”€â”€ requirements.txt     # DependÃªncias Python
â”œâ”€â”€ .gitignore          # Arquivos ignorados pelo Git
â””â”€â”€ README.md
```

## ğŸ“Š Dados de Exemplo

### vendas.csv (5 colunas)
- `id`, `produto`, `categoria`, `preco`, `quantidade`

### clientes.csv (6 colunas)  
- `id`, `nome`, `email`, `categoria`, `regiao`, `data_cadastro`

### Colunas Comuns para Join
- `id` e `categoria`

## âš¡ Resumo RÃ¡pido

```bash
# 1. Setup inicial
./scripts/setup-dev.sh

# 2. Teste local
./scripts/test-local.sh

# 3. Deploy na AWS
./scripts/deploy.sh

# 4. Executar no AWS Glue
./scripts/run-glue-job.sh

# 5. Limpar recursos (quando terminar)
./scripts/destroy.sh
```

## ğŸš€ Como Usar

### PrÃ©-requisitos

1. **AWS CLI configurado**:
   ```bash
   aws configure
   # Configure: Access Key, Secret Key, Region (recomendado: us-east-1), Output format
   ```

2. **Terraform instalado**:
   ```bash
   # macOS
   brew install terraform
   
   # Ubuntu/Debian
   sudo apt-get update && sudo apt-get install -y terraform
   
   # Ou baixe de: https://terraform.io/downloads
   ```

3. **Python 3** (para testes locais) - SerÃ¡ configurado automaticamente com venv

### ğŸ”§ Fluxo Completo de Uso

#### **Passo 0: Configurar Ambiente de Desenvolvimento (primeira vez)**

```bash
./scripts/setup-dev.sh
```

#### **Passo 1: Teste Local**

Execute o processamento localmente para validar a lÃ³gica usando o mesmo script do Glue:

```bash
# Usando o script de conveniÃªncia (recomendado)
./scripts/test-local.sh

# Ou manualmente ativando o venv
source venv/bin/activate
python src/glue_job.py local
deactivate

# Ou usando variÃ¡vel de ambiente
source venv/bin/activate
ENVIRONMENT=local python src/glue_job.py
deactivate
```

O resultado serÃ¡ salvo em `output/vendas_clientes_merged.csv`.

#### **Passo 2: Deploy na AWS**

#### **Primeira vez ou mudanÃ§as na infraestrutura:**
```bash
./scripts/deploy.sh
```

Este comando irÃ¡:
- âœ… Verificar prÃ©-requisitos (Terraform, AWS CLI)
- âœ… Inicializar Terraform
- âœ… Criar bucket S3 Ãºnico
- âœ… Fazer upload do script Python atualizado
- âœ… Fazer upload dos arquivos CSV de exemplo
- âœ… Criar job AWS Glue com configuraÃ§Ã£o otimizada para baixo custo
- âœ… Criar roles e polÃ­ticas IAM necessÃ¡rias
- âœ… Exibir informaÃ§Ãµes do deployment

#### **Atualizar apenas o script Python:**
```bash
cd terraform
terraform apply -auto-approve
```

#### **Passo 3: Executar Job AWS Glue**

```bash
./scripts/run-glue-job.sh
```

Este script irÃ¡:
- ğŸš€ Iniciar o job no AWS Glue
- ğŸ“Š Monitorar a execuÃ§Ã£o em tempo real
- âœ… Informar quando concluÃ­do
- ğŸ“ Mostrar onde encontrar os resultados

#### **Passo 4: Baixar Resultados (Opcional)**

```bash
# Obter nome do bucket e baixar resultados
cd terraform
BUCKET_NAME=$(terraform output -raw s3_bucket_name)
aws s3 cp s3://$BUCKET_NAME/output/ ./output/ --recursive
```

#### **Passo 5: Verificar ConfiguraÃ§Ã£o AWS (Se NecessÃ¡rio)**

```bash
# Verificar se AWS CLI estÃ¡ configurado
aws sts get-caller-identity

# Se nÃ£o estiver configurado:
aws configure
```

#### **Passo 6: Destruir Infraestrutura (Quando Finalizar)**

```bash
./scripts/destroy.sh
```

âš ï¸ **ATENÃ‡ÃƒO**: Este comando remove TODOS os recursos AWS criados, incluindo o bucket S3 e todos os arquivos.

## ğŸ’° OtimizaÃ§Ã£o de Custos

A POC estÃ¡ configurada para minimizar custos:

- **Worker Type**: G.1X (menor tipo disponÃ­vel)
- **Number of Workers**: 2 (mÃ­nimo)
- **Timeout**: 5 minutos
- **Job Bookmark**: Desabilitado
- **Auto Scaling**: Desabilitado

**Custo estimado**: ~$0.44 por execuÃ§Ã£o (regiÃ£o us-east-1)

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis Terraform

Edite `terraform/variables.tf` para personalizar:

```hcl
variable "aws_region" {
  default = "us-east-1"  # Altere a regiÃ£o se necessÃ¡rio
}

variable "glue_job_timeout" {
  default = 5  # Timeout em minutos
}

variable "max_capacity" {
  default = 2  # NÃºmero de workers
}
```

### Modo de ExecuÃ§Ã£o do Script Python

O script `src/glue_job.py` suporta execuÃ§Ã£o em ambos os ambientes usando um Ãºnico arquivo:

**Arquitetura do Script:**

O script `glue_job.py` foi projetado com uma arquitetura que garante **idÃªntica lÃ³gica de processamento** em ambos os ambientes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AMBIENTE LOCAL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ load_data_local() â†’ process_data() â†’ save_data_local()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AMBIENTE AWS GLUE                        â”‚ 
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ load_data_glue() â†’ process_data() â†’ save_data_glue()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **`process_data()`**: ContÃ©m 100% da lÃ³gica de negÃ³cio usando pandas
- **Input/Output**: Apenas estas funÃ§Ãµes diferem entre ambientes
- **Garantia**: Mesmas regras executadas independente do ambiente

**ExecuÃ§Ã£o Local:**
```bash
# Usando parÃ¢metro
python3 src/glue_job.py local

# Usando variÃ¡vel de ambiente  
ENVIRONMENT=local python3 src/glue_job.py
```

**ExecuÃ§Ã£o no AWS Glue:**
- Detecta automaticamente o ambiente AWS Glue
- Converte Spark DataFrames para pandas para usar a mesma lÃ³gica
- Reconverte para Spark apenas no momento de salvar

## ğŸ“ Logs e Monitoramento

### CloudWatch Logs
```bash
# Ver logs do job
aws logs describe-log-groups --log-group-name-prefix "/aws-glue/jobs"
```

### Status do Job
```bash
# Listar execuÃ§Ãµes do job
aws glue get-job-runs --job-name csv-merger-job
```

## ğŸ” Troubleshooting

### Erro: "Job failed"
1. Verifique os logs no CloudWatch
2. Confirme que os arquivos CSV estÃ£o no bucket S3
3. Verifique permissÃµes IAM

### Erro: "Bucket already exists"
- O nome do bucket Ã© gerado aleatoriamente, mas se houver conflito, execute `terraform destroy` e `terraform apply` novamente

### Teste local falha
- Verifique se o pandas estÃ¡ instalado: `pip install pandas`
- Confirme que os arquivos CSV estÃ£o em `tests/files/`

## ğŸ¯ PrÃ³ximos Passos

Para evoluir esta POC:

1. **Adicionar mais transformaÃ§Ãµes**: Limpeza de dados, validaÃ§Ãµes
2. **Implementar particionamento**: Para datasets maiores
3. **Adicionar testes automatizados**: ValidaÃ§Ã£o de esquemas
4. **Configurar CI/CD**: Deploy automatizado
5. **Adicionar monitoramento**: Alertas e mÃ©tricas customizadas
6. **Implementar Data Catalog**: Para descoberta de dados

## ğŸ“œ LicenÃ§a

Este projeto Ã© uma POC para fins educacionais e de demonstraÃ§Ã£o.