# POC AWS Glue - CSV Merger

Esta Ã© uma Prova de Conceito (POC) para demonstrar como usar AWS Glue para processar e combinar arquivos CSV usando Terraform para infraestrutura como cÃ³digo.

## ğŸ“‹ DescriÃ§Ã£o

O projeto cria um job AWS Glue que:
- LÃª 2 arquivos CSV de um bucket S3
- Combina os arquivos pelas colunas comuns (`id` e `categoria`)
- Salva o resultado em um novo arquivo CSV no S3
- Suporte para testes locais usando pandas

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 Bucket     â”‚    â”‚   AWS Glue      â”‚    â”‚   S3 Bucket     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  input/         â”‚â”€â”€â”€â–¶â”‚  CSV Merger Job â”‚â”€â”€â”€â–¶â”‚  output/        â”‚
â”‚  â”œâ”€ vendas.csv  â”‚    â”‚                 â”‚    â”‚  â””â”€ merged.csv  â”‚
â”‚  â””â”€ clientes.csvâ”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
poc-glue-tests/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ glue_job.py       # Script principal do Glue (funciona local + AWS)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ files/
â”‚       â”œâ”€â”€ vendas.csv    # Arquivo CSV de exemplo (5 colunas)
â”‚       â””â”€â”€ clientes.csv  # Arquivo CSV de exemplo (6 colunas)
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf          # ConfiguraÃ§Ã£o principal
â”‚   â”œâ”€â”€ variables.tf     # VariÃ¡veis
â”‚   â””â”€â”€ outputs.tf       # Outputs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-dev.sh     # Configurar ambiente de desenvolvimento
â”‚   â”œâ”€â”€ deploy.sh        # Script de deploy
â”‚   â”œâ”€â”€ destroy.sh       # Script de destruiÃ§Ã£o
â”‚   â”œâ”€â”€ test-local.sh    # Script de teste local
â”‚   â””â”€â”€ run-glue-job.sh  # Script para executar job
â”œâ”€â”€ venv/                # Ambiente virtual Python (criado automaticamente)
â”œâ”€â”€ output/              # Pasta para resultados locais
â”œâ”€â”€ requirements.txt     # DependÃªncias Python
â”œâ”€â”€ .gitignore          # Arquivos ignorados pelo Git
â””â”€â”€ README.md
```

## ğŸ“Š Dados de Exemplo

### vendas.csv (5 colunas)
- `id`, `produto`, `categoria`, `preco`, `quantidade`

### clientes.csv (6 colunas)  
- `id`, `nome`, `email`, `categoria`, `regiao`, `data_cadastro`

### Colunas Comuns para Join
- `id` e `categoria`

## ğŸš€ Como Usar

### PrÃ©-requisitos

1. **AWS CLI configurado**:
   ```bash
   aws configure
   ```

2. **Terraform instalado**:
   ```bash
   # macOS
   brew install terraform
   
   # Ou baixe de: https://terraform.io/downloads
   ```

3. **Python 3** (para testes locais) - SerÃ¡ configurado automaticamente com venv

### 0. Configurar Ambiente de Desenvolvimento (primeira vez)

```bash
./scripts/setup-dev.sh
```

### 1. Teste Local

Execute o processamento localmente para validar a lÃ³gica usando o mesmo script do Glue:

```bash
# Usando o script de conveniÃªncia (recomendado)
./scripts/test-local.sh

# Ou manualmente ativando o venv
source venv/bin/activate
python src/glue_job.py local
deactivate

# Ou usando variÃ¡vel de ambiente
source venv/bin/activate
ENVIRONMENT=local python src/glue_job.py
deactivate
```

O resultado serÃ¡ salvo em `output/vendas_clientes_merged.csv`.

### 2. Deploy na AWS

```bash
./scripts/deploy.sh
```

Este comando irÃ¡:
- Criar bucket S3 Ãºnico
- Fazer upload dos scripts e arquivos CSV
- Criar job AWS Glue com configuraÃ§Ã£o otimizada para baixo custo
- Criar roles e polÃ­ticas IAM necessÃ¡rias

### 3. Executar Job AWS Glue

```bash
./scripts/run-glue-job.sh
```

Este script irÃ¡:
- Iniciar o job no AWS Glue
- Monitorar a execuÃ§Ã£o
- Informar quando concluÃ­do

### 4. Baixar Resultados

```bash
# Obter nome do bucket
cd terraform
BUCKET_NAME=$(terraform output -raw s3_bucket_name)

# Baixar resultados
aws s3 cp s3://$BUCKET_NAME/output/ ./output/ --recursive
```

### 5. Destruir Infraestrutura

```bash
./scripts/destroy.sh
```

âš ï¸ **ATENÃ‡ÃƒO**: Este comando remove TODOS os recursos AWS criados, incluindo o bucket S3 e todos os arquivos.

## ğŸ’° OtimizaÃ§Ã£o de Custos

A POC estÃ¡ configurada para minimizar custos:

- **Worker Type**: G.1X (menor tipo disponÃ­vel)
- **Number of Workers**: 2 (mÃ­nimo)
- **Timeout**: 5 minutos
- **Job Bookmark**: Desabilitado
- **Auto Scaling**: Desabilitado

**Custo estimado**: ~$0.44 por execuÃ§Ã£o (regiÃ£o us-east-1)

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis Terraform

Edite `terraform/variables.tf` para personalizar:

```hcl
variable "aws_region" {
  default = "us-east-1"  # Altere a regiÃ£o se necessÃ¡rio
}

variable "glue_job_timeout" {
  default = 5  # Timeout em minutos
}

variable "max_capacity" {
  default = 2  # NÃºmero de workers
}
```

### Modo de ExecuÃ§Ã£o do Script Python

O script `src/glue_job.py` suporta execuÃ§Ã£o em ambos os ambientes usando um Ãºnico arquivo:

**ExecuÃ§Ã£o Local:**
```bash
# Usando parÃ¢metro
python3 src/glue_job.py local

# Usando variÃ¡vel de ambiente
ENVIRONMENT=local python3 src/glue_job.py
```

**ExecuÃ§Ã£o no AWS Glue:**
- O script detecta automaticamente quando estÃ¡ sendo executado no AWS Glue
- Usa as bibliotecas do Glue (pyspark, awsglue) quando disponÃ­veis
- Se as bibliotecas nÃ£o estiverem disponÃ­veis, sugere execuÃ§Ã£o em modo local

## ğŸ“ Logs e Monitoramento

### CloudWatch Logs
```bash
# Ver logs do job
aws logs describe-log-groups --log-group-name-prefix "/aws-glue/jobs"
```

### Status do Job
```bash
# Listar execuÃ§Ãµes do job
aws glue get-job-runs --job-name csv-merger-job
```

## ğŸ” Troubleshooting

### Erro: "Job failed"
1. Verifique os logs no CloudWatch
2. Confirme que os arquivos CSV estÃ£o no bucket S3
3. Verifique permissÃµes IAM

### Erro: "Bucket already exists"
- O nome do bucket Ã© gerado aleatoriamente, mas se houver conflito, execute `terraform destroy` e `terraform apply` novamente

### Teste local falha
- Verifique se o pandas estÃ¡ instalado: `pip install pandas`
- Confirme que os arquivos CSV estÃ£o em `tests/files/`

## ğŸ¯ PrÃ³ximos Passos

Para evoluir esta POC:

1. **Adicionar mais transformaÃ§Ãµes**: Limpeza de dados, validaÃ§Ãµes
2. **Implementar particionamento**: Para datasets maiores
3. **Adicionar testes automatizados**: ValidaÃ§Ã£o de esquemas
4. **Configurar CI/CD**: Deploy automatizado
5. **Adicionar monitoramento**: Alertas e mÃ©tricas customizadas
6. **Implementar Data Catalog**: Para descoberta de dados

## ğŸ“œ LicenÃ§a

Este projeto Ã© uma POC para fins educacionais e de demonstraÃ§Ã£o.